{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d9c155-ccff-4608-9de3-50b1085c54de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#CREATE MARKET BASKET FORMAT\n",
    "# Create a view with all transactions (baskets)\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW market_baskets AS\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.user_id,\n",
    "    COLLECT_LIST(p.product_name) as products,\n",
    "    COLLECT_LIST(op.product_id) as product_ids,\n",
    "    COUNT(*) as basket_size\n",
    "FROM workspace.instacart.orders o\n",
    "JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "JOIN workspace.instacart.products p ON op.product_id = p.product_id\n",
    "WHERE o.eval_set = 'prior'\n",
    "GROUP BY o.order_id, o.user_id\n",
    "HAVING basket_size >= 2\n",
    "\"\"\")\n",
    "display(spark.table('market_baskets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "912e2b6b-7621-4221-84ad-d3df452a17ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# PART 2: PYSPARK ASSOCIATION ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark Session (already available in Databricks)\n",
    "spark = SparkSession.builder.appName(\"InstacartAssociation\").getOrCreate()\n",
    "\n",
    "# 1. Prepare transaction data for FP-Growth\n",
    "def prepare_transactions_for_fpgrowth():\n",
    "    \"\"\"\n",
    "    Prepare data in the format required by FP-Growth algorithm\n",
    "    \"\"\"\n",
    "    transactions_df = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            o.order_id,\n",
    "            COLLECT_LIST(CAST(op.product_id AS STRING)) as items\n",
    "        FROM workspace.instacart.orders o\n",
    "        JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "        WHERE o.eval_set = 'prior'\n",
    "        GROUP BY o.order_id\n",
    "        HAVING COUNT(*) >= 2\n",
    "        LIMIT 100000  -- Start with subset for faster processing\n",
    "    \"\"\")\n",
    "    \n",
    "    return transactions_df\n",
    "\n",
    "# 2. Run FP-Growth Algorithm\n",
    "def run_fpgrowth_analysis(transactions_df, min_support=0.001, min_confidence=0.1):\n",
    "    \"\"\"\n",
    "    Run FP-Growth algorithm to find frequent itemsets and association rules\n",
    "    \n",
    "    Parameters:\n",
    "    - min_support: Minimum support threshold (default 0.1% of transactions)\n",
    "    - min_confidence: Minimum confidence for association rules\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create FP-Growth model\n",
    "    fpGrowth = FPGrowth(\n",
    "        itemsCol=\"items\", \n",
    "        minSupport=min_support, \n",
    "        minConfidence=min_confidence\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model = fpGrowth.fit(transactions_df)\n",
    "    \n",
    "    # Get frequent itemsets\n",
    "    frequent_itemsets = model.freqItemsets\n",
    "    \n",
    "    # Get association rules\n",
    "    association_rules = model.associationRules\n",
    "    \n",
    "    return frequent_itemsets, association_rules, model\n",
    "\n",
    "# 3. Analyze Association Rules with Product Names\n",
    "def analyze_rules_with_names(association_rules):\n",
    "    \"\"\"\n",
    "    Join association rules with product names for better interpretation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a product lookup table\n",
    "    products_lookup = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            CAST(product_id AS STRING) as product_id,\n",
    "            product_name,\n",
    "            aisle_id,\n",
    "            department_id\n",
    "        FROM workspace.instacart.products\n",
    "    \"\"\")\n",
    "    \n",
    "    # Convert rules to a more interpretable format\n",
    "    rules_expanded = association_rules.select(\n",
    "        col(\"antecedent\").alias(\"antecedent_ids\"),\n",
    "        col(\"consequent\").alias(\"consequent_ids\"),\n",
    "        col(\"confidence\"),\n",
    "        col(\"lift\"),\n",
    "        col(\"support\")\n",
    "    )\n",
    "    \n",
    "    return rules_expanded\n",
    "\n",
    "# 4. Find Product Associations for Specific Products\n",
    "def find_product_associations(product_name_pattern):\n",
    "    \"\"\"\n",
    "    Find associations for products matching a name pattern\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH product_pairs AS (\n",
    "        SELECT \n",
    "            op1.product_id as product1_id,\n",
    "            op2.product_id as product2_id,\n",
    "            COUNT(DISTINCT op1.order_id) as co_occurrence_count\n",
    "        FROM workspace.instacart.order_products_prior op1\n",
    "        JOIN workspace.instacart.order_products_prior op2 \n",
    "            ON op1.order_id = op2.order_id \n",
    "            AND op1.product_id < op2.product_id\n",
    "        GROUP BY op1.product_id, op2.product_id\n",
    "        HAVING co_occurrence_count > 50\n",
    "    ),\n",
    "    product_support AS (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            COUNT(DISTINCT order_id) as support_count\n",
    "        FROM workspace.instacart.order_products_prior\n",
    "        GROUP BY product_id\n",
    "    )\n",
    "    SELECT \n",
    "        p1.product_name as product_1,\n",
    "        p2.product_name as product_2,\n",
    "        pp.co_occurrence_count,\n",
    "        ps1.support_count as product1_count,\n",
    "        ps2.support_count as product2_count,\n",
    "        ROUND(pp.co_occurrence_count * 1.0 / ps1.support_count, 4) as confidence_1_to_2,\n",
    "        ROUND(pp.co_occurrence_count * 1.0 / ps2.support_count, 4) as confidence_2_to_1,\n",
    "        ROUND(pp.co_occurrence_count * 1.0 * \n",
    "            (SELECT COUNT(DISTINCT order_id) FROM workspace.instacart.order_products_prior) / \n",
    "            (ps1.support_count * ps2.support_count), 4) as lift\n",
    "    FROM product_pairs pp\n",
    "    JOIN workspace.instacart.products p1 ON pp.product1_id = p1.product_id\n",
    "    JOIN workspace.instacart.products p2 ON pp.product2_id = p2.product_id\n",
    "    JOIN product_support ps1 ON pp.product1_id = ps1.product_id\n",
    "    JOIN product_support ps2 ON pp.product2_id = ps2.product_id\n",
    "    WHERE p1.product_name LIKE '%{product_name_pattern}%'\n",
    "       OR p2.product_name LIKE '%{product_name_pattern}%'\n",
    "    ORDER BY lift DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "    \n",
    "    return spark.sql(query)\n",
    "\n",
    "# 5. Department-Level Association Analysis\n",
    "def department_association_analysis():\n",
    "    \"\"\"\n",
    "    Analyze associations at department level for broader patterns\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    WITH dept_baskets AS (\n",
    "        SELECT \n",
    "            o.order_id,\n",
    "            d.department,\n",
    "            COUNT(DISTINCT op.product_id) as items_from_dept\n",
    "        FROM workspace.instacart.orders o\n",
    "        JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "        JOIN workspace.instacart.products p ON op.product_id = p.product_id\n",
    "        JOIN workspace.instacart.departments d ON p.department_id = d.department_id\n",
    "        WHERE o.eval_set = 'prior'\n",
    "        GROUP BY o.order_id, d.department\n",
    "    ),\n",
    "    dept_pairs AS (\n",
    "        SELECT \n",
    "            db1.department as dept1,\n",
    "            db2.department as dept2,\n",
    "            COUNT(DISTINCT db1.order_id) as co_occurrence,\n",
    "            COUNT(DISTINCT db1.order_id) * 1.0 / \n",
    "                (SELECT COUNT(DISTINCT order_id) FROM dept_baskets) as support\n",
    "        FROM dept_baskets db1\n",
    "        JOIN dept_baskets db2 ON db1.order_id = db2.order_id\n",
    "        WHERE db1.department < db2.department\n",
    "        GROUP BY db1.department, db2.department\n",
    "        HAVING co_occurrence > 1000\n",
    "    )\n",
    "    SELECT \n",
    "        dept1,\n",
    "        dept2,\n",
    "        co_occurrence,\n",
    "        ROUND(support * 100, 2) as support_pct,\n",
    "        ROUND(co_occurrence * 1.0 / \n",
    "            (SELECT COUNT(DISTINCT order_id) FROM dept_baskets WHERE department = dept1), 4) as confidence_dept1_to_dept2\n",
    "    FROM dept_pairs\n",
    "    ORDER BY co_occurrence DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "    \n",
    "    return spark.sql(query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd7932e-6607-4e5e-9832-6f7b15e4a8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 4: RECOMMENDATION SYSTEM\n",
    "# ============================================\n",
    "\n",
    "def create_product_recommendations(user_id, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Create personalized recommendations for a specific user\n",
    "    based on their purchase history and association rules\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get user's purchase history\n",
    "    user_history_query = f\"\"\"\n",
    "    SELECT DISTINCT p.product_id, p.product_name, COUNT(*) as purchase_count\n",
    "    FROM workspace.instacart.orders o\n",
    "    JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "    JOIN workspace.instacart.products p ON op.product_id = p.product_id\n",
    "    WHERE o.user_id = {user_id}\n",
    "    GROUP BY p.product_id, p.product_name\n",
    "    ORDER BY purchase_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get frequently associated products\n",
    "    recommendations_query = f\"\"\"\n",
    "    WITH user_products AS (\n",
    "        SELECT DISTINCT op.product_id\n",
    "        FROM workspace.instacart.orders o\n",
    "        JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "        WHERE o.user_id = {user_id}\n",
    "    ),\n",
    "    associated_products AS (\n",
    "        SELECT \n",
    "            op2.product_id as recommended_product,\n",
    "            COUNT(DISTINCT op1.order_id) as association_strength\n",
    "        FROM workspace.instacart.order_products_prior op1\n",
    "        JOIN workspace.instacart.order_products_prior op2 \n",
    "            ON op1.order_id = op2.order_id\n",
    "        WHERE op1.product_id IN (SELECT product_id FROM user_products)\n",
    "          AND op2.product_id NOT IN (SELECT product_id FROM user_products)\n",
    "        GROUP BY op2.product_id\n",
    "    )\n",
    "    SELECT \n",
    "        p.product_name,\n",
    "        p.product_id,\n",
    "        a.aisle,\n",
    "        d.department,\n",
    "        ap.association_strength,\n",
    "        RANK() OVER (ORDER BY ap.association_strength DESC) as recommendation_rank\n",
    "    FROM associated_products ap\n",
    "    JOIN workspace.instacart.products p ON ap.recommended_product = p.product_id\n",
    "    JOIN workspace.instacart.aisles a ON p.aisle_id = a.aisle_id\n",
    "    JOIN workspace.instacart.departments d ON p.department_id = d.department_id\n",
    "    ORDER BY association_strength DESC\n",
    "    LIMIT {n_recommendations}\n",
    "    \"\"\"\n",
    "    \n",
    "    user_history = spark.sql(user_history_query)\n",
    "    recommendations = spark.sql(recommendations_query)\n",
    "    \n",
    "    return user_history, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def40783-fe9a-4169-980d-a034c96347be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 5: EVALUATION METRICS\n",
    "# ============================================\n",
    "\n",
    "def calculate_recommendation_metrics():\n",
    "    \"\"\"\n",
    "    Calculate metrics to evaluate recommendation quality\n",
    "    using the train set as ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics_query = \"\"\"\n",
    "    WITH train_baskets AS (\n",
    "        SELECT \n",
    "            o.user_id,\n",
    "            COLLECT_SET(op.product_id) as actual_products\n",
    "        FROM workspace.instacart.orders o\n",
    "        JOIN workspace.instacart.order_products_train op ON o.order_id = op.order_id\n",
    "        GROUP BY o.user_id\n",
    "    ),\n",
    "    prior_frequent AS (\n",
    "        SELECT \n",
    "            o.user_id,\n",
    "            op.product_id,\n",
    "            COUNT(*) as purchase_frequency,\n",
    "            ROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY COUNT(*) DESC) as rank\n",
    "        FROM workspace.instacart.orders o\n",
    "        JOIN workspace.instacart.order_products_prior op ON o.order_id = op.order_id\n",
    "        GROUP BY o.user_id, op.product_id\n",
    "    ),\n",
    "    recommendations AS (\n",
    "        SELECT \n",
    "            user_id,\n",
    "            COLLECT_LIST(product_id) as recommended_products\n",
    "        FROM prior_frequent\n",
    "        WHERE rank <= 10\n",
    "        GROUP BY user_id\n",
    "    )\n",
    "    SELECT \n",
    "        COUNT(*) as total_users,\n",
    "        AVG(SIZE(array_intersect(t.actual_products, r.recommended_products))) as avg_correct_predictions,\n",
    "        AVG(SIZE(array_intersect(t.actual_products, r.recommended_products)) / SIZE(r.recommended_products)) as avg_precision,\n",
    "        AVG(SIZE(array_intersect(t.actual_products, r.recommended_products)) / SIZE(t.actual_products)) as avg_recall\n",
    "    FROM train_baskets t\n",
    "    JOIN recommendations r ON t.user_id = r.user_id\n",
    "    \"\"\"\n",
    "    \n",
    "    return spark.sql(metrics_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44b4bc3-bde0-4fbf-a941-9ff0949bfb46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 6: MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function - run this to perform complete analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"1. Preparing transaction data...\")\n",
    "    transactions = prepare_transactions_for_fpgrowth()\n",
    "    print(f\"   Total transactions: {transactions.count()}\")\n",
    "    \n",
    "    print(\"\\n2. Running FP-Growth algorithm...\")\n",
    "    freq_items, rules, model = run_fpgrowth_analysis(transactions)\n",
    "    print(f\"   Frequent itemsets found: {freq_items.count()}\")\n",
    "    print(f\"   Association rules found: {rules.count()}\")\n",
    "    \n",
    "    print(\"\\n3. Top association rules by lift:\")\n",
    "    rules.orderBy(col(\"lift\").desc()).show(20, truncate=False)\n",
    "    \n",
    "    print(\"\\n4. Department-level associations:\")\n",
    "    dept_associations = department_association_analysis()\n",
    "    dept_associations.show(20, truncate=False)\n",
    "    \n",
    "    print(\"\\n5. Sample product associations (for 'Banana'):\")\n",
    "    banana_associations = find_product_associations('Banana')\n",
    "    banana_associations.show(20, truncate=False)\n",
    "    \n",
    "    print(\"\\n6. Calculating recommendation metrics:\")\n",
    "    metrics = calculate_recommendation_metrics()\n",
    "    metrics.show()\n",
    "    \n",
    "    return freq_items, rules, model\n",
    "\n",
    "# Execute the analysis\n",
    "# Uncomment the line below to run the complete analysis\n",
    "# frequent_itemsets, association_rules, fpgrowth_model = main()\n",
    "\n",
    "# ============================================\n",
    "# PART 7: VISUALIZATIONS (Using Databricks Display)\n",
    "# ============================================\n",
    "\n",
    "# After running the analysis, use these for visualization:\n",
    "\n",
    "# Create the top_associations view in Python using spark.sql()\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW top_associations AS\n",
    "WITH product_pairs AS (\n",
    "    SELECT \n",
    "        op1.product_id as product1_id,\n",
    "        op2.product_id as product2_id,\n",
    "        COUNT(DISTINCT op1.order_id) as co_occurrence\n",
    "    FROM workspace.instacart.order_products_prior op1\n",
    "    JOIN workspace.instacart.order_products_prior op2 \n",
    "        ON op1.order_id = op2.order_id \n",
    "        AND op1.product_id < op2.product_id\n",
    "    GROUP BY op1.product_id, op2.product_id\n",
    "    HAVING co_occurrence > 100\n",
    ")\n",
    "SELECT \n",
    "    CONCAT(p1.product_name, ' → ', p2.product_name) as product_pair,\n",
    "    pp.co_occurrence,\n",
    "    ROUND(pp.co_occurrence * 1.0 / \n",
    "        (SELECT COUNT(DISTINCT order_id) FROM workspace.instacart.order_products_prior), 4) as support\n",
    "FROM product_pairs pp\n",
    "JOIN workspace.instacart.products p1 ON pp.product1_id = p1.product_id\n",
    "JOIN workspace.instacart.products p2 ON pp.product2_id = p2.product_id\n",
    "ORDER BY co_occurrence DESC\n",
    "LIMIT 30\n",
    "\"\"\")\n",
    "\n",
    "# Display the results\n",
    "display(spark.table(\"top_associations\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "760ff91d-3110-4f3d-8488-5cc50910c372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 8: EXPORT RESULTS\n",
    "# ============================================\n",
    "\n",
    "def export_association_rules(rules_df, output_path=\"/tmp/association_rules\"):\n",
    "    \"\"\"\n",
    "    Export association rules to CSV for external analysis\n",
    "    \"\"\"\n",
    "    # Convert to Pandas for easier manipulation\n",
    "    rules_pd = rules_df.toPandas()\n",
    "    \n",
    "    # Save to CSV\n",
    "    rules_pd.to_csv(f\"{output_path}.csv\", index=False)\n",
    "    print(f\"Association rules exported to {output_path}.csv\")\n",
    "    \n",
    "    # Also save as Delta table for future use\n",
    "    rules_df.write.mode(\"overwrite\").saveAsTable(\"workspace.instacart.association_rules\")\n",
    "    print(\"Association rules saved as Delta table: workspace.instacart.association_rules\")\n",
    "    \n",
    "    return rules_pd"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Association_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
